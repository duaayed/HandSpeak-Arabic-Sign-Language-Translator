{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed0ab2a-c649-44cb-b0ee-14651c19cdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keypoint collection started.\n",
      "1/1 [==============================] - 14s 14s/step\n",
      "Prediction: يكسر (Confidence: 0.94)\n",
      "Keypoint collection stopped.\n",
      "Keypoint collection started.\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Prediction: فك الإحرام (Confidence: 0.96)\n",
      "Keypoint collection stopped.\n",
      "Keypoint collection started.\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Prediction: مجمد (فريزر) (Confidence: 1.00)\n",
      "Keypoint collection stopped.\n",
      "Keypoint collection started.\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Prediction: كرسي (Confidence: 1.00)\n",
      "Keypoint collection stopped.\n",
      "Keypoint collection started.\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Prediction: كرسي (Confidence: 1.00)\n",
      "Keypoint collection stopped.\n",
      "Keypoint collection started.\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Keypoint collection stopped.\n",
      "Keypoint collection started.\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Keypoint collection stopped.\n",
      "Keypoint collection started.\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Prediction: كرسي (Confidence: 1.00)\n",
      "Keypoint collection stopped.\n",
      "Keypoint collection started.\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction: بين (Confidence: 0.97)\n",
      "Keypoint collection stopped.\n",
      "Keypoint collection started.\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Prediction: حمل (Confidence: 0.94)\n",
      "Keypoint collection stopped.\n",
      "Keypoint collection started.\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction: حكة / هرش (Confidence: 1.00)\n",
      "Keypoint collection stopped.\n",
      "Keypoint collection started.\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Prediction: الزكاة (Confidence: 0.97)\n",
      "Keypoint collection stopped.\n",
      "Keypoint collection started.\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Keypoint collection stopped.\n",
      "Keypoint collection started.\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Prediction: يساعد (Confidence: 0.92)\n",
      "Keypoint collection stopped.\n",
      "Keypoint collection started.\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Keypoint collection stopped.\n",
      "Keypoint collection started.\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Prediction: يساعد (Confidence: 0.91)\n",
      "Keypoint collection stopped.\n",
      "Keypoint collection started.\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Prediction: مخدر/ بنج (Confidence: 0.98)\n",
      "Keypoint collection stopped.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from keras.models import load_model\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import arabic_reshaper\n",
    "from bidi.algorithm import get_display\n",
    "import json\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('working/LSTM_Model_1.h5')\n",
    "\n",
    "# Load label map\n",
    "with open(\"working/label_map.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    label_map = json.load(file)\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# Path to Arabic font file\n",
    "font_path = \"working/Adobe Arabic Regular.ttf\"\n",
    "font = ImageFont.truetype(font_path, 32)\n",
    "\n",
    "# Initialize MediaPipe Holistic\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to adjust landmarks based on a reference point\n",
    "def adjust_landmarks(landmarks, center):\n",
    "    if len(landmarks) == 0:\n",
    "        return np.zeros_like(center)\n",
    "    landmarks = landmarks.reshape(-1, 3)\n",
    "    center_repeated = np.tile(center, (len(landmarks), 1))\n",
    "    adjusted_landmarks = landmarks - center_repeated\n",
    "    return adjusted_landmarks.flatten()\n",
    "\n",
    "# Function to extract and adjust keypoints\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33 * 3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21 * 3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21 * 3)\n",
    "    nose = pose[:3] if len(pose) >= 3 else np.zeros(3)\n",
    "    pose_adjusted = adjust_landmarks(pose, nose)\n",
    "    lh_adjusted = adjust_landmarks(lh, lh[:3] if len(lh) >= 3 else np.zeros(3))\n",
    "    rh_adjusted = adjust_landmarks(rh, rh[:3] if len(rh) >= 3 else np.zeros(3))\n",
    "    return np.concatenate([pose_adjusted, lh_adjusted, rh_adjusted])\n",
    "\n",
    "# Function to detect gestures confidently\n",
    "def is_gesture_detected(lh, rh):\n",
    "    def bounding_box_area(hand_landmarks):\n",
    "        if len(hand_landmarks) == 0:\n",
    "            return 0\n",
    "        x_coords = hand_landmarks[::3]\n",
    "        y_coords = hand_landmarks[1::3]\n",
    "        return (np.max(x_coords) - np.min(x_coords)) * (np.max(y_coords) - np.min(y_coords))\n",
    "    lh_area = bounding_box_area(lh)\n",
    "    rh_area = bounding_box_area(rh)\n",
    "    return lh_area > 0.01 or rh_area > 0.01\n",
    "\n",
    "# Real-time gesture recognition with toggle functionality\n",
    "sequence = []\n",
    "sequence_length = 48\n",
    "last_prediction = \"\"\n",
    "collecting = False  # Flag to track whether keypoint collection is active\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(frame_rgb)\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "        mp_drawing.draw_landmarks(frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        mp_drawing.draw_landmarks(frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "        # Handle key press to toggle collection\n",
    "        key = cv2.waitKey(10) & 0xFF\n",
    "        if key == ord('s'):  # Press 's' to toggle collection\n",
    "            collecting = not collecting\n",
    "            if not collecting:\n",
    "                # Reset sequence and clear prediction when stopping collection\n",
    "                sequence = []\n",
    "                last_prediction = \"\"\n",
    "                print(\"Keypoint collection stopped.\")\n",
    "            else:\n",
    "                print(\"Keypoint collection started.\")\n",
    "\n",
    "        # Collect keypoints if collection is active\n",
    "        if collecting:\n",
    "            keypoints = extract_keypoints(results)\n",
    "            sequence.append(keypoints)\n",
    "\n",
    "            if len(sequence) > sequence_length:\n",
    "                sequence = sequence[-sequence_length:]\n",
    "\n",
    "            if len(sequence) == sequence_length:\n",
    "                input_sequence = np.expand_dims(np.array(sequence), axis=0)\n",
    "                prediction = model.predict(input_sequence)\n",
    "                predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "                confidence = np.max(prediction)\n",
    "\n",
    "                if confidence > 0.7:  # Confidence threshold\n",
    "                    last_prediction = reverse_label_map[predicted_class]\n",
    "                    print(f\"Prediction: {last_prediction} (Confidence: {confidence:.2f})\")\n",
    "\n",
    "                # Reset sequence after prediction\n",
    "                sequence = []\n",
    "\n",
    "        # Display feedback\n",
    "        status_text = \"Collecting\" if collecting else \"Idle\"\n",
    "        reshaped_text = arabic_reshaper.reshape(last_prediction)\n",
    "        bidi_text = get_display(reshaped_text)\n",
    "        frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        draw = ImageDraw.Draw(frame_pil)\n",
    "        draw.text((10, 50), f\"Status: {status_text}\", font=font, fill=(0, 255, 0))\n",
    "        draw.text((10, 100), bidi_text, font=font, fill=(255, 0, 0))\n",
    "        frame = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        cv2.imshow('ترجمة لغة الإشارة العربية', frame)\n",
    "\n",
    "        if key == ord('q'):  # Press 'q' to quit\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Predicted Word: {last_prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa54b002-e658-4ca3-b027-6e42ddd6b8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
